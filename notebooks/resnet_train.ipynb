{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj1HMR2dnUS3"
      },
      "source": [
        "# –§–∞–∑–∞ 2 ‚Ä¢ –ù–µ–¥–µ–ª—è 8 ‚Ä¢ –ß–µ—Ç–≤–µ—Ä–≥\n",
        "## –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n",
        "### üî• PyTorch: fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN8mJgEonUS8"
      },
      "source": [
        "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Ä–∞–±–æ—Ç–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏ —ç—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –Ω–∞ Google Colab\n",
        "2. –ü–æ–¥–≥—Ä—É–∑–∏ –∞—Ä—Ö–∏–≤ [–¥–∞—Ç–∞—Å–µ—Ç–∞](https://www.kaggle.com/datasets/ikobzev/architectural-heritage-elements-image64-dataset) –≤ —Å–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏ —Ä–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä—É–π –µ–≥–æ —Å –ø–æ–º–æ—â—å—é `unzip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F_CC8e0rnUS-"
      },
      "outputs": [],
      "source": [
        "!unzip -qq /content/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install torchutils"
      ],
      "metadata": {
        "id": "XGh6XNeuro-7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "\n",
        "# –î–ª—è —á—Ç–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –¥–∏—Å–∫–∞\n",
        "from torchvision import io # input/output\n",
        "import torchutils as tu\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "z2evudkmrcDV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uwjBj--nUTA"
      },
      "source": [
        "1. –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ª–∏–±–æ –ø—Ä–∏–≤–µ–¥–∏—Ç–µ –µ–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É, —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –Ω–∏–∂–µ):\n",
        "\n",
        "        `train`\n",
        "        \n",
        "            - class_1\n",
        "            - class_2\n",
        "            - ...\n",
        "            - class_n\n",
        "            \n",
        "        `valid`\n",
        "\n",
        "            - class_1\n",
        "            - class_2\n",
        "            - ...\n",
        "            - class_n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name \".ipynb_checkpoints\" -type d -exec rm -r {} +"
      ],
      "metadata": {
        "id": "6i3dwICN2Xs6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qyt32unDnUTB"
      },
      "outputs": [],
      "source": [
        "# transform = T.Compose([\n",
        "#     T.Resize((224, 224)),\n",
        "#     T.ToTensor(),\n",
        "#     T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "# ])\n",
        "\n",
        "\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.RandomHorizontalFlip(p=0.5),         # –°–ª—É—á–∞–π–Ω–æ–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ\n",
        "    T.RandomRotation(degrees=20),          # –°–ª—É—á–∞–π–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç –¥–æ 20 –≥—Ä–∞–¥—É—Å–æ–≤\n",
        "    T.RandomResizedCrop(size=224, scale=(0.8, 1.0)),  # –û–±—Ä–µ–∑–∫–∞ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞\n",
        "    T.ToTensor(),                          # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä\n",
        "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "])\n",
        "\n",
        "# –î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "valid_transforms = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# –î–∞—Ç–∞—Å–µ—Ç—ã\n",
        "train_dataset = datasets.ImageFolder(root='/content/seg_train', transform=train_transforms)\n",
        "valid_dataset = datasets.ImageFolder(root='/content/seg_test', transform=valid_transforms)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9BBhaWcnUTC"
      },
      "source": [
        "2. –°–æ–∑–¥–∞–π `DataLoader` –≤ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "f-yRSnqShWGq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvMVegAjnUTF"
      },
      "source": [
        "3. –°–æ–∑–¥–∞–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: [torchvision models](https://pytorch.org/vision/stable/models.html). –ú–æ–∂–Ω–æ –≤–∑—è—Ç—å –ª—é–±—É—é –º–æ–¥–µ–ª—å –¥–ª—è baseline, –∞ –¥–∞–ª—å—à–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —á—Ç–æ-—Ç–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HpngKzkJnUTF"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT).to(DEVICE)\n",
        "\n",
        "fake_batch = torch.randn(4, 3, 224, 224, device=DEVICE)\n",
        "tu.get_model_summary(model, fake_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8wOd1EJ_hcDF",
        "outputId": "2f84dd2e-98a2-44e4-8cb5-8d5337ac813c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 189MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================================================================================================\n",
            "Layer                                       Kernel             Output          Params           FLOPs\n",
            "=====================================================================================================\n",
            "0_conv1                                   [3, 64, 7, 7]   [4, 64, 112, 112]       9,408   472,055,808\n",
            "1_bn1                                              [64]   [4, 64, 112, 112]         128    12,845,056\n",
            "2_relu                                                -   [4, 64, 112, 112]           0             0\n",
            "3_maxpool                                             -     [4, 64, 56, 56]           0             0\n",
            "4_layer1.0.Conv2d_conv1                  [64, 64, 3, 3]     [4, 64, 56, 56]      36,864   462,422,016\n",
            "5_layer1.0.BatchNorm2d_bn1                         [64]     [4, 64, 56, 56]         128     3,211,264\n",
            "6_layer1.0.ReLU_relu                                  -     [4, 64, 56, 56]           0             0\n",
            "7_layer1.0.Conv2d_conv2                  [64, 64, 3, 3]     [4, 64, 56, 56]      36,864   462,422,016\n",
            "8_layer1.0.BatchNorm2d_bn2                         [64]     [4, 64, 56, 56]         128     3,211,264\n",
            "9_layer1.0.ReLU_relu                                  -     [4, 64, 56, 56]           0             0\n",
            "10_layer1.1.Conv2d_conv1                 [64, 64, 3, 3]     [4, 64, 56, 56]      36,864   462,422,016\n",
            "11_layer1.1.BatchNorm2d_bn1                        [64]     [4, 64, 56, 56]         128     3,211,264\n",
            "12_layer1.1.ReLU_relu                                 -     [4, 64, 56, 56]           0             0\n",
            "13_layer1.1.Conv2d_conv2                 [64, 64, 3, 3]     [4, 64, 56, 56]      36,864   462,422,016\n",
            "14_layer1.1.BatchNorm2d_bn2                        [64]     [4, 64, 56, 56]         128     3,211,264\n",
            "15_layer1.1.ReLU_relu                                 -     [4, 64, 56, 56]           0             0\n",
            "16_layer2.0.Conv2d_conv1                [64, 128, 3, 3]    [4, 128, 28, 28]      73,728   231,211,008\n",
            "17_layer2.0.BatchNorm2d_bn1                       [128]    [4, 128, 28, 28]         256     1,605,632\n",
            "18_layer2.0.ReLU_relu                                 -    [4, 128, 28, 28]           0             0\n",
            "19_layer2.0.Conv2d_conv2               [128, 128, 3, 3]    [4, 128, 28, 28]     147,456   462,422,016\n",
            "20_layer2.0.BatchNorm2d_bn2                       [128]    [4, 128, 28, 28]         256     1,605,632\n",
            "21_layer2.0.downsample.Conv2d_0         [64, 128, 1, 1]    [4, 128, 28, 28]       8,192    25,690,112\n",
            "22_layer2.0.downsample.BatchNorm2d_1              [128]    [4, 128, 28, 28]         256     1,605,632\n",
            "23_layer2.0.ReLU_relu                                 -    [4, 128, 28, 28]           0             0\n",
            "24_layer2.1.Conv2d_conv1               [128, 128, 3, 3]    [4, 128, 28, 28]     147,456   462,422,016\n",
            "25_layer2.1.BatchNorm2d_bn1                       [128]    [4, 128, 28, 28]         256     1,605,632\n",
            "26_layer2.1.ReLU_relu                                 -    [4, 128, 28, 28]           0             0\n",
            "27_layer2.1.Conv2d_conv2               [128, 128, 3, 3]    [4, 128, 28, 28]     147,456   462,422,016\n",
            "28_layer2.1.BatchNorm2d_bn2                       [128]    [4, 128, 28, 28]         256     1,605,632\n",
            "29_layer2.1.ReLU_relu                                 -    [4, 128, 28, 28]           0             0\n",
            "30_layer3.0.Conv2d_conv1               [128, 256, 3, 3]    [4, 256, 14, 14]     294,912   231,211,008\n",
            "31_layer3.0.BatchNorm2d_bn1                       [256]    [4, 256, 14, 14]         512       802,816\n",
            "32_layer3.0.ReLU_relu                                 -    [4, 256, 14, 14]           0             0\n",
            "33_layer3.0.Conv2d_conv2               [256, 256, 3, 3]    [4, 256, 14, 14]     589,824   462,422,016\n",
            "34_layer3.0.BatchNorm2d_bn2                       [256]    [4, 256, 14, 14]         512       802,816\n",
            "35_layer3.0.downsample.Conv2d_0        [128, 256, 1, 1]    [4, 256, 14, 14]      32,768    25,690,112\n",
            "36_layer3.0.downsample.BatchNorm2d_1              [256]    [4, 256, 14, 14]         512       802,816\n",
            "37_layer3.0.ReLU_relu                                 -    [4, 256, 14, 14]           0             0\n",
            "38_layer3.1.Conv2d_conv1               [256, 256, 3, 3]    [4, 256, 14, 14]     589,824   462,422,016\n",
            "39_layer3.1.BatchNorm2d_bn1                       [256]    [4, 256, 14, 14]         512       802,816\n",
            "40_layer3.1.ReLU_relu                                 -    [4, 256, 14, 14]           0             0\n",
            "41_layer3.1.Conv2d_conv2               [256, 256, 3, 3]    [4, 256, 14, 14]     589,824   462,422,016\n",
            "42_layer3.1.BatchNorm2d_bn2                       [256]    [4, 256, 14, 14]         512       802,816\n",
            "43_layer3.1.ReLU_relu                                 -    [4, 256, 14, 14]           0             0\n",
            "44_layer4.0.Conv2d_conv1               [256, 512, 3, 3]      [4, 512, 7, 7]   1,179,648   231,211,008\n",
            "45_layer4.0.BatchNorm2d_bn1                       [512]      [4, 512, 7, 7]       1,024       401,408\n",
            "46_layer4.0.ReLU_relu                                 -      [4, 512, 7, 7]           0             0\n",
            "47_layer4.0.Conv2d_conv2               [512, 512, 3, 3]      [4, 512, 7, 7]   2,359,296   462,422,016\n",
            "48_layer4.0.BatchNorm2d_bn2                       [512]      [4, 512, 7, 7]       1,024       401,408\n",
            "49_layer4.0.downsample.Conv2d_0        [256, 512, 1, 1]      [4, 512, 7, 7]     131,072    25,690,112\n",
            "50_layer4.0.downsample.BatchNorm2d_1              [512]      [4, 512, 7, 7]       1,024       401,408\n",
            "51_layer4.0.ReLU_relu                                 -      [4, 512, 7, 7]           0             0\n",
            "52_layer4.1.Conv2d_conv1               [512, 512, 3, 3]      [4, 512, 7, 7]   2,359,296   462,422,016\n",
            "53_layer4.1.BatchNorm2d_bn1                       [512]      [4, 512, 7, 7]       1,024       401,408\n",
            "54_layer4.1.ReLU_relu                                 -      [4, 512, 7, 7]           0             0\n",
            "55_layer4.1.Conv2d_conv2               [512, 512, 3, 3]      [4, 512, 7, 7]   2,359,296   462,422,016\n",
            "56_layer4.1.BatchNorm2d_bn2                       [512]      [4, 512, 7, 7]       1,024       401,408\n",
            "57_layer4.1.ReLU_relu                                 -      [4, 512, 7, 7]           0             0\n",
            "58_avgpool                                            -      [4, 512, 1, 1]           0       102,400\n",
            "59_fc                                       [512, 1000]           [4, 1000]     513,000     4,092,000\n",
            "=====================================================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "Total FLOPs: 7,298,179,168 / 7.30 GFLOPs\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "Input size (MB): 2.30\n",
            "Forward/backward pass size (MB): 228.20\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 275.09\n",
            "=====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjhBXdsdnUTG"
      },
      "source": [
        "5. –ó–∞–º–µ–Ω–∏ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ñ–æ—Ä–º–∞—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –∑–∞–¥–∞—á—É: –±–∏–Ω–∞—Ä–Ω–∞—è –∏–ª–∏ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RETC3O6fnUTH"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(512, 6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    print(param.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aNFYfJmOh_OU",
        "outputId": "a27364f9-e594-4d71-c97a-3162702dc1d7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "se3qjjFQipmi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc.weight.requires_grad = True\n",
        "model.fc.bias.requires_grad = True"
      ],
      "metadata": {
        "id": "hVNtb2qZi-zV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trnsfrms = T.Compose(\n",
        "    [\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor() # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø–∏–∫—Å–µ–ª–µ–π –±—É–¥–µ—Ç 0-1\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "eb-iWE63k_hM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "mRC4W4tglRrQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9ZgMJ02nUTI"
      },
      "source": [
        "6. –û–±—É—á–∏ –º–æ–¥–µ–ª—å (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π!) –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–π –º–µ—Ç—Ä–∏–∫—É –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –≤—ã–±–æ—Ä–∫–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "sxLHEfwsnUTI",
        "outputId": "57b6377c-b86a-401d-e8ef-14549d36890b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Tensor' object has no attribute 'loat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-63a2b8ff4ad8>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'loat'"
          ]
        }
      ],
      "source": [
        "train_epoch_acc = []\n",
        "train_epoch_losses = []\n",
        "valid_epoch_losses = []\n",
        "valid_epoch_acc =[]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    loss_batch = []\n",
        "    acc_batch  = []\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(model.fc.weight.device)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º device –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏\n",
        "        labels = labels.to(model.fc.weight.device)\n",
        "\n",
        "        preds = model(images).squeeze(-1)\n",
        "        loss = criterion(preds, labels.long())\n",
        "        loss_batch.append(loss.item())\n",
        "        accuracy = (preds.argmax(dim=1) == labels).cpu().numpy().mean()\n",
        "        # accuracy = (preds.sigmoid().round() == labels).cpu().numpy().mean()\n",
        "        acc_batch.append(accuracy)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_epoch_losses.append(np.mean(loss_batch))\n",
        "    train_epoch_acc.append(np.mean(acc_batch))\n",
        "\n",
        "    model.eval()\n",
        "    loss_batch = []\n",
        "    acc_batch  = []\n",
        "    for images, labels in valid_loader:\n",
        "        images = images.to(model.fc.weight.device)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º device –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏\n",
        "        labels = labels.to(model.fc.weight.device)\n",
        "        with torch.no_grad():\n",
        "            preds = model(images).squeeze(-1)\n",
        "\n",
        "        loss = criterion(preds, labels.long())\n",
        "        loss_batch.append(loss.item())\n",
        "\n",
        "        # accuracy = (preds.sigmoid().round() == labels).cpu().numpy().mean()\n",
        "        accuracy = (preds.argmax(dim=1) == labels).cpu().numpy().mean()\n",
        "        acc_batch.append(accuracy)\n",
        "\n",
        "    valid_epoch_losses.append(np.mean(loss_batch))\n",
        "    valid_epoch_acc.append(np.mean(acc_batch))\n",
        "\n",
        "    print(f'Epoch: {epoch}  loss_train: {train_epoch_losses[-1]:.3f}, loss_valid: {valid_epoch_losses[-1]:.3f}')\n",
        "    print(f'\\t  metrics_train: {train_epoch_acc[-1]:.3f}, metrics_valid: {valid_epoch_acc[-1]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqfZM8XhnUTI"
      },
      "source": [
        "7. –†–∞—Å–ø–µ—á–∞—Ç–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –ø–æ–¥–ø–∏—à–∏ –∫–ª–∞—Å—Å –∫–∞—Ä—Ç–∏–Ω–∫–∏, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –º–æ–¥–µ–ª—å—é."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaEYjntDnUTJ"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRzdxbLDnUTJ"
      },
      "source": [
        "8. \"–†–∞–∑–º–æ—Ä–æ–∑—å\" –Ω–µ—Å–æ–∫–ª—å–∫–æ —Å–ª–æ–µ–≤ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏ –≤–Ω–æ–≤—å –æ–±—É—á–∏ –µ–µ. –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π –º–µ—Ç—Ä–∏–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –º–æ–¥–µ–ª–∏. –û —Ç–æ–º, –∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å unfreeze –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–µ–≤ —Å—Ä–∞–∑—É, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ, –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å —Ç—É—Ç: [discuss.pytorch.org](https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088/3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK7KPzTbnUTJ"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3XGGrA9nUTJ"
      },
      "source": [
        "9. –°—Ä–∞–≤–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π: –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º –≤—ã—Ö–æ–¥–Ω—ã–º —Å–ª–æ–µ–º –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏ —Å–ª–æ—è–º–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHDgaM1wnUTK"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBPDcFzCnUTK"
      },
      "source": [
        "<img src=\"https://icons.iconarchive.com/icons/icons8/windows-8/256/Programming-Github-icon.png\" width=32 /> –°–æ—Ö—Ä–∞–Ω–∏ —Ñ–∞–π–ª –¥–ª—è __github__ –∏ —Ä–∞—Å–ø–µ—á–∞—Ç–∞–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–º–∞–Ω–¥—ã `!git status` –≤ —è—á–µ–π–∫–µ –Ω–∏–∂–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX95HgP7nUTK"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbdNdLYRnUTL"
      },
      "source": [
        "10. –°–æ—Ö—Ä–∞–Ω–∏ –º–æ–¥–µ–ª—å (–ø—Ä–∏–º–µ—Ä –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å [—Ç—É—Ç](../../learning/aux/model_saving.ipynb) –∏–ª–∏ –≤ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://pytorch.org/tutorials/beginner/saving_loading_models.html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z9cDOKlnUTL"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4erk4swnUTL"
      },
      "source": [
        "11. –†–µ–∞–ª–∏–∑—É–π —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞ –≤—Ö–æ–¥ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∞ –≤ –æ—Ç–≤–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∞—Å—Å –æ–±—ä–µ–∫—Ç–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEMeYa3xnUTM"
      },
      "outputs": [],
      "source": [
        "def get_prediction(path: str) -> str:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je2POb0inUTM"
      },
      "source": [
        "12. –°–æ—Ö—Ä–∞–Ω–∏ –Ω–æ—É—Ç–±—É–∫ –Ω–∞ github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efPnN-i7nUTM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "73ec0c878552fcb71893c22b7af2c9be9210ef33785c90eb804f443984ec4506"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}